{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d724cf",
   "metadata": {},
   "source": [
    "## Installing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cb14b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (4.51.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: wandb in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (0.19.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (5.29.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch transformers datasets wandb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16ad5df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (78.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: wheel in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (0.45.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: wandb in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (0.19.9)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (5.29.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (78.1.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from wandb) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: huggingface_hub[hf_xet] in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (0.30.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from huggingface_hub[hf_xet]) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from huggingface_hub[hf_xet]) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from huggingface_hub[hf_xet]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from huggingface_hub[hf_xet]) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from huggingface_hub[hf_xet]) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from huggingface_hub[hf_xet]) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from huggingface_hub[hf_xet]) (4.13.2)\n",
      "Requirement already satisfied: hf-xet>=0.1.4 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from huggingface_hub[hf_xet]) (1.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub[hf_xet]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hshakademie7\\desktop\\intocode weiterbildung\\generative_al_project\\.venv\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install setuptools\n",
    "%pip install wheel\n",
    "%pip install wandb\n",
    "%pip install huggingface_hub[hf_xet]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aa7d08",
   "metadata": {},
   "source": [
    "## importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9957026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "import wandb\n",
    "from huggingface_hub import HfApi, HfFolder, Repository\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd3befa",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca42ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    block_size = 128\n",
    "    batch_size = 32\n",
    "    embed_dim = 128\n",
    "    num_heads = 4\n",
    "    num_layers = 2\n",
    "    dropout = 0.1\n",
    "    epochs = 5\n",
    "    lr = 1e-3\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    wandb_project = \"tiny-shakespeare-decoder-only\"\n",
    "    model_name = \"decoder-only-tinyshakespeare\"\n",
    "\n",
    "cfg = Config()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b0d05",
   "metadata": {},
   "source": [
    "## Preparing and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f24a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "data_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "with open(\"shakespeare.txt\", \"w\") as f:\n",
    "    f.write(requests.get(data_url).text)\n",
    "\n",
    "with open(\"shakespeare.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "from transformers import GPT2TokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e56009",
   "metadata": {},
   "source": [
    "## Loading   Tokenizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ee6f513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (338025 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "\n",
    "\n",
    "tokens = tokenizer(text, return_tensors=\"pt\")\n",
    "input_ids = tokens[\"input_ids\"].squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a39a4b8",
   "metadata": {},
   "source": [
    "## spliting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3cfe4099",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = int(0.9 * len(input_ids))\n",
    "train_ids = input_ids[:n]\n",
    "val_ids = input_ids[n:]\n",
    "\n",
    "def get_batch(data, block_size, batch_size):\n",
    "    if len(data) <= block_size:\n",
    "        raise ValueError(f\"Datensatz ist zu klein für block_size={block_size} (nur {len(data)} Tokens).\")\n",
    "\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x.to(cfg.device), y.to(cfg.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc36e38",
   "metadata": {},
   "source": [
    "## Decoder-only Modell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e422d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecoderOnlyModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, cfg.embed_dim)\n",
    "        self.pos_embedding = nn.Parameter(torch.zeros(1, cfg.block_size, cfg.embed_dim))\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=cfg.embed_dim, nhead=cfg.num_heads, dropout=cfg.dropout)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=cfg.num_layers)\n",
    "\n",
    "        self.output_proj = nn.Linear(cfg.embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        tok_emb = self.embedding(x)\n",
    "        pos_emb = self.pos_embedding[:, :x.size(1), :]\n",
    "        x = tok_emb + pos_emb\n",
    "\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(x.size(1)).to(x.device)\n",
    "\n",
    "        # Autoregressives Target als sowohl memory als auch tgt\n",
    "        out = self.decoder(x.transpose(0, 1), x.transpose(0, 1), tgt_mask=tgt_mask)\n",
    "        logits = self.output_proj(out.transpose(0, 1))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9bf79497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"d2a634cf8a08029fc63ddf4ff73e2da22ac1c1e0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44786f78",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "96c40a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▄▃▂▁</td></tr><tr><td>val_loss</td><td>▇▅▅█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>train_loss</td><td>3.34305</td></tr><tr><td>val_loss</td><td>4.32956</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glad-darkness-11</strong> at: <a href='https://wandb.ai/juliennemizero1-hsh/tiny-shakespeare-decoder-only/runs/2adoqtbu' target=\"_blank\">https://wandb.ai/juliennemizero1-hsh/tiny-shakespeare-decoder-only/runs/2adoqtbu</a><br> View project at: <a href='https://wandb.ai/juliennemizero1-hsh/tiny-shakespeare-decoder-only' target=\"_blank\">https://wandb.ai/juliennemizero1-hsh/tiny-shakespeare-decoder-only</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250419_134128-2adoqtbu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\hshakademie7\\Desktop\\INTOCODE WEITERBILDUNG\\Generative_Al_project\\GenerativeAI-Project\\wandb\\run-20250423_133216-sqys5sbv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/juliennemizero1-hsh/tiny-shakespeare-decoder-only/runs/sqys5sbv' target=\"_blank\">earthy-dawn-12</a></strong> to <a href='https://wandb.ai/juliennemizero1-hsh/tiny-shakespeare-decoder-only' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/juliennemizero1-hsh/tiny-shakespeare-decoder-only' target=\"_blank\">https://wandb.ai/juliennemizero1-hsh/tiny-shakespeare-decoder-only</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/juliennemizero1-hsh/tiny-shakespeare-decoder-only/runs/sqys5sbv' target=\"_blank\">https://wandb.ai/juliennemizero1-hsh/tiny-shakespeare-decoder-only/runs/sqys5sbv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 5.7444 | Val Loss = 5.3130\n",
      "Epoch 2: Train Loss = 4.3734 | Val Loss = 4.7451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 3.9457 | Val Loss = 4.5034\n",
      "Epoch 4: Train Loss = 3.6516 | Val Loss = 4.8341\n",
      "Epoch 5: Train Loss = 3.3423 | Val Loss = 4.6937\n",
      "Epoch 6: Train Loss = 3.0237 | Val Loss = 4.4508\n"
     ]
    }
   ],
   "source": [
    "#  Training preparation\n",
    "model = DecoderOnlyModel(vocab_size=tokenizer.vocab_size).to(cfg.device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "import wandb\n",
    "wandb.init(project=cfg.wandb_project, config=vars(cfg))\n",
    "\n",
    "# raining Loop\n",
    "for epoch in range(6):  \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step in range(200):  \n",
    "        x, y = get_batch(train_ids, cfg.block_size, cfg.batch_size)\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / 200\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_x, val_y = get_batch(val_ids, cfg.block_size, cfg.batch_size)\n",
    "        val_logits = model(val_x)\n",
    "        val_loss = loss_fn(val_logits.view(-1, val_logits.size(-1)), val_y.view(-1)).item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f} | Val Loss = {val_loss:.4f}\")\n",
    "    wandb.log({\"train_loss\": avg_train_loss, \"val_loss\": val_loss, \"epoch\": epoch+1})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26290902",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a66feaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " long time ago his power\n",
      "The senate his power his mighty man his dev:\n",
      "From his power\n",
      "The power had swallow his power\n",
      "Nor his power\n",
      "The realm for his power\n",
      "The each his power,\n",
      "war begin his power dead and his power and freshest his power:\n",
      "The Rome,\n",
      " sovereign? and his tent his power? and bl with his power and his charge?\n",
      "\n",
      " his mother? and his, mark his new-wh tongue his? and lam?, who deny his\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, tokenizer, prompt, max_new_tokens=50, temperature=1.0):\n",
    "    model.eval()\n",
    "    generated = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(cfg.device)\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        input_ids = generated[:, -cfg.block_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids)\n",
    "        logits = logits[:, -1, :] / temperature  \n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        next_token = torch.multinomial(probs, num_samples=1)\n",
    "        generated = torch.cat((generated, next_token), dim=1)\n",
    "    \n",
    "    return tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "\n",
    "prompt = \" long time ago\"\n",
    "output = generate_text(model, tokenizer, prompt, max_new_tokens=100)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55a60bd",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "04ceb965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from huggingface_hub import HfApi, HfFolder, upload_folder, create_repo\n",
    "\n",
    "save_dir = \"decoder-gpt-julienne\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "#  Save model weights\n",
    "torch.save(model.state_dict(), os.path.join(save_dir, \"pytorch_model.bin\"))\n",
    "\n",
    "#  Save tokenizer\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "#  Save model config\n",
    "model_config = {\n",
    "    \"model_type\": \"decoder-only\",\n",
    "    \"vocab_size\": tokenizer.vocab_size,\n",
    "    \"embed_dim\": cfg.embed_dim,\n",
    "    \"num_heads\": cfg.num_heads,\n",
    "    \"num_layers\": cfg.num_layers,\n",
    "    \"dropout\": cfg.dropout,\n",
    "    \"block_size\": cfg.block_size\n",
    "}\n",
    "with open(os.path.join(save_dir, \"config.json\"), \"w\") as f:\n",
    "    json.dump(model_config, f)\n",
    "\n",
    "# README.md\n",
    "with open(os.path.join(save_dir, \"README.md\"), \"w\") as f:\n",
    "    f.write(\n",
    "        \"# Decoder Only GPT by Julienne Mizero\\n\"\n",
    "        \"This repository contains a decoder-only GPT model fine-tuned by Julienne Mizero. The model is designed to be used for various text generation tasks.\"\n",
    "        \"#Model Description\\n\"\n",
    "        \"The decoder-only GPT model is a generative language model that is based on the transformer architecture. It is fine-tuned on a specific dataset to improve its ability to generate coherent text based on a given prompt.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af43211c",
   "metadata": {},
   "source": [
    "## Uploading to Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7ee9d690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hshakademie7\\Desktop\\INTOCODE WEITERBILDUNG\\Generative_Al_project\\.venv\\Lib\\site-packages\\huggingface_hub\\hf_api.py:9561: UserWarning: Warnings while validating metadata in README.md:\n",
      "- empty or missing yaml metadata in repo card\n",
      "  warnings.warn(f\"Warnings while validating metadata in README.md:\\n{message}\")\n",
      "pytorch_model.bin: 100%|██████████| 57.0M/57.0M [01:21<00:00, 700kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Upload finished!\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login, upload_folder\n",
    "import os\n",
    "\n",
    "# Your Hugging Face token\n",
    "HUGGINGFACE_TOKEN = \"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\"\n",
    "\n",
    "# Login to Hugging Face\n",
    "login(token=HUGGINGFACE_TOKEN)\n",
    "\n",
    "#  Your Hugging Face username\n",
    "username = \"JulienneMizero\"\n",
    "\n",
    "# Define repo info (Include the username in repo_id)\n",
    "repo_name = \"decoder-gpt-julienne\"\n",
    "repo_id = f\"{username}/{repo_name}\"  # Correct repo ID format\n",
    "\n",
    "# Define the model folder path (replace with the actual folder you want to upload)\n",
    "model_folder = r\"C:\\Users\\hshakademie7\\Desktop\\INTOCODE WEITERBILDUNG\\Generative_Al_project\\GenerativeAI-Project\\decoder-gpt-julienne\"\n",
    "\n",
    "# Check if the folder exists\n",
    "if not os.path.isdir(model_folder):\n",
    "    raise FileNotFoundError(f\"Folder '{model_folder}' not found!\")\n",
    "\n",
    "# Upload the folder to your repo\n",
    "upload_folder(\n",
    "    repo_id=repo_id,\n",
    "    folder_path=model_folder,  # This should be the local path to your model folder\n",
    "    path_in_repo=\"https://huggingface.co/JulienneMizero/decoder-gpt-julienne\",  # Upload everything at the root of the repo\n",
    "    commit_message=\"Upload model from Julienne\"\n",
    ")\n",
    "\n",
    "print(\" Upload finished!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
