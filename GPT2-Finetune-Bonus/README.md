
## Projekt: Fine-Tuning von GPT-2 auf Tiny Shakespeare (Bonus)
Das GPT-2 Modell wurde auf dem Tiny Shakespeare-Datensatz mittels Fine-Tuning mit PyTorch trainiert.
Das Modell wurde für den Einsatz auf CPUs optimiert.

## Highlights:
* Fine-Tuning von GPT-2 auf Shakespeare-Texte.
* Protokollierung der Verlustwerte (loss) und Ergebnisse über Weights & Biases.
* pload des trainierten Modells auf Hugging Face.


## Links:

### Hugging Face: [Hier klicken](https://huggingface.co/rahaf-aswad/gpt2-finetuned-shakespeare_bonu)

### Weights & Biases: [Hier klicken](https://wandb.ai/rahaf-aswad-hochschule-hannover/gpt2-finetuned-shakespeare_bonus)
